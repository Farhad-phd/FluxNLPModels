var documenterSearchIndex = {"docs":
[{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/#Contents","page":"Reference","title":"Contents","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [FluxNLPModels]","category":"page"},{"location":"reference/#FluxNLPModels.FluxNLPModel","page":"Reference","title":"FluxNLPModels.FluxNLPModel","text":"FluxNLPModel{T, S, C <: Flux.Chain} <: AbstractNLPModel{T, S}\n\nData structure that makes the interfaces between neural networks defined with Flux.jl and NLPModels. A FluxNLPModel has fields\n\nArguments\n\nmeta and counters retain informations about the FluxNLPModel;\nchain is the chained structure representing the neural network;\ndata_train is the complete data training set;\ndata_test is the complete data test;\nsize_minibatch parametrizes the size of an training and test minibatches\ntraining_minibatch_iterator is an iterator over an training minibatches;\ntest_minibatch_iterator is an iterator over the test minibatches;\ncurrent_training_minibatch is the training minibatch used to evaluate the neural network;\ncurrent_minibatch_test is the current test minibatch, it is not used in practice;\nw is the vector of weights/variables;\n\n\n\n\n\n","category":"type"},{"location":"reference/#FluxNLPModels.FluxNLPModel-Union{Tuple{F}, Tuple{T}, Tuple{T, Any, Any}} where {T<:Flux.Chain, F<:Function}","page":"Reference","title":"FluxNLPModels.FluxNLPModel","text":"FluxNLPModel(chain_ANN data_train=MLDatasets.MNIST.traindata(Float32), data_test=MLDatasets.MNIST.testdata(Float32); size_minibatch=100)\n\nBuild a FluxNLPModel from the neural network represented by chain_ANN. chain_ANN is built using Flux.jl for more details. The other data required are: an iterator over the training dataset data_train, an iterator over the test dataset data_test and the size of the minibatch size_minibatch. Suppose (xtrn,ytrn) = Fluxnlp.data_train\n\n\n\n\n\n","category":"method"},{"location":"reference/#FluxNLPModels.accuracy-Union{Tuple{AbstractFluxNLPModel{T, S}}, Tuple{S}, Tuple{T}} where {T, S}","page":"Reference","title":"FluxNLPModels.accuracy","text":"accuracy(nlp::AbstractFluxNLPModel)\n\nCompute the accuracy of the network nlp.chain on the entire test dataset. data_loader can be overwritten to include other data,  device is set to cpu \n\n\n\n\n\n","category":"method"},{"location":"reference/#FluxNLPModels.minibatch_next_test!-Tuple{AbstractFluxNLPModel}","page":"Reference","title":"FluxNLPModels.minibatch_next_test!","text":"minibatch_next_test!(nlp::AbstractFluxNLPModel)\n\nSelects the next minibatch from nlp.test_minibatch_iterator.   Returns the new current status of the iterator nlp.current_test_minibatch. minibatch_next_test! aims to be used in a loop or method call. if return false, it means that it reach the end of the mini-batch\n\n\n\n\n\n","category":"method"},{"location":"reference/#FluxNLPModels.minibatch_next_train!-Tuple{AbstractFluxNLPModel}","page":"Reference","title":"FluxNLPModels.minibatch_next_train!","text":"minibatch_next_train!(nlp::AbstractFluxNLPModel)\n\nSelects the next minibatch from nlp.training_minibatch_iterator.   Returns the new current status of the iterator nlp.current_training_minibatch. minibatch_next_train! aims to be used in a loop or method call. if return false, it means that it reach the end of the mini-batch\n\n\n\n\n\n","category":"method"},{"location":"reference/#FluxNLPModels.reset_minibatch_test!-Tuple{AbstractFluxNLPModel}","page":"Reference","title":"FluxNLPModels.reset_minibatch_test!","text":"reset_minibatch_test!(nlp::AbstractFluxNLPModel)\n\nIf a data_loader (an iterator object is passed to FluxNLPModel) then  Select the first test minibatch for nlp.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FluxNLPModels.reset_minibatch_train!-Tuple{AbstractFluxNLPModel}","page":"Reference","title":"FluxNLPModels.reset_minibatch_train!","text":"reset_minibatch_train!(nlp::AbstractFluxNLPModel)\n\nIf a data_loader (an iterator object is passed to FluxNLPModel) then  Select the first training minibatch for nlp.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FluxNLPModels.set_vars!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractFluxNLPModel{T, S}, AbstractVector{T}}} where {T<:Number, S}","page":"Reference","title":"FluxNLPModels.set_vars!","text":"set_vars!(model::AbstractFluxNLPModel{T,S}, new_w::AbstractVector{T}) where {T<:Number, S}\n\nSets the vaiables and rebuild the chain\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.grad!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractFluxNLPModel{T, S}, AbstractVector{T}, AbstractVector{T}}} where {T, S}","page":"Reference","title":"NLPModels.grad!","text":"g = grad!(nlp, x, g)\n\nEvaluate ∇f(x), the gradient of the objective function at x in place.\n\nArguments\n\nnlp::AbstractFluxNLPModel{T, S}: the FluxNLPModel data struct\nw::AbstractVector{T}: is the vector of weights/variables;\n\n-g::AbstractVector{T}: the gradient vector\n\nOutput\n\ng: the gradient at point x\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.obj-Union{Tuple{S}, Tuple{T}, Tuple{AbstractFluxNLPModel{T, S}, AbstractVector{T}}} where {T, S}","page":"Reference","title":"NLPModels.obj","text":"f = obj(nlp, x)\n\nEvaluate f(x), the objective function of nlp at x.\n\nArguments\n\nnlp::AbstractFluxNLPModel{T, S}: the FluxNLPModel data struct\nw::AbstractVector{T}: is the vector of weights/variables;\n\nOutput\n\nf_w: the new objective function\n\n\n\n\n\n","category":"method"},{"location":"reference/#NLPModels.objgrad!-Union{Tuple{S}, Tuple{T}, Tuple{AbstractFluxNLPModel{T, S}, AbstractVector{T}, AbstractVector{T}}} where {T, S}","page":"Reference","title":"NLPModels.objgrad!","text":"objgrad!(nlp, x, g)\n\nEvaluate both `f(x)`, the objective function of `nlp` at `x` and `∇f(x)`, the gradient of the objective function at `x` in place.\n\nArguments\n\nnlp::AbstractFluxNLPModel{T, S}: the FluxNLPModel data struct\nw::AbstractVector{T}: is the vector of weights/variables;\n\n-g::AbstractVector{T}: the gradient vector\n\nOutput\n\nf_w, g: the new objective function, and the gradient at point x\n\n\n\n\n\n","category":"method"},{"location":"","page":"Home","title":"Home","text":"#TODO redo this section ","category":"page"},{"location":"#FluxNLPModels.jl","page":"Home","title":"FluxNLPModels.jl","text":"","category":"section"},{"location":"#Compatibility","page":"Home","title":"Compatibility","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Julia ≥ 1.6.","category":"page"},{"location":"#How-to-install","page":"Home","title":"How to install","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"TODO: this section needs work since our package is not yet register This module can be installed with the following command:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# pkg> add FluxNLPModels\n# pkg> test FluxNLPModels","category":"page"},{"location":"#Synopsis","page":"Home","title":"Synopsis","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"FluxNLPModels exposes neural network models as optimization problems conforming to the NLPModels.jl API. FluxNLPModels is an interface between Flux.jl's classification neural networks and NLPModels.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A FluxNLPModel gives the user access to:","category":"page"},{"location":"","page":"Home","title":"Home","text":"The values of the neural network variables/weights w;\nThe value of the objective/loss function L(X, Y; w) at w for a given minibatch (X,Y);\nThe gradient ∇L(X, Y; w) of the objective/loss function at w for a given minibatch (X,Y).","category":"page"},{"location":"","page":"Home","title":"Home","text":"In addition, it provides tools to:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Switch the minibatch used to evaluate the neural network;\nRetrieve the current minibatch ;\nMeasure the neural network's loss at the current w.","category":"page"},{"location":"#How-to-use","page":"Home","title":"How to use","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Check the tutorials <!– Check the tutorial. –>","category":"page"},{"location":"#Bug-reports-and-discussions","page":"Home","title":"Bug reports and discussions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you think you found a bug, feel free to open an [issue]<!–(https://github.com/JuliaSmoothOptimizers/FluxNLPModels.jl/issues). –> TODO: add repo link Focused suggestions and requests can also be opened as issues. Before opening a pull request, please start an issue or a discussion on the topic.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you have a question that is not suited for a bug report, feel free to start a discussion here. This forum is for general discussion about this repository and the JuliaSmoothOptimizers. Questions about any of our packages are welcome.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Hello","category":"page"}]
}
